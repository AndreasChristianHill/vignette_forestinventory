% !Rnw root = JStatSoft_forestinventory_master.Rnw

% set global options for R-output:
<<echo=FALSE>>=
options(prompt = "R> ", continue = "+  ", width = 77, useFancyQuotes = FALSE)
@

\section{Two-phase estimators and their application}
\label{sec:twophase_and_appl}


% ---------------------------------------------------------------------------- %
\subsection{Global estimators}
\label{sec:twophase_globest}

\subsubsection{Mathematical background}

The vector of regression coefficients of the OLS regression model is found by using the following solution to the sample-based normal equation:

\begin{equation}\label{normequ_simple}
  \hat{\pmb{\beta}}_{s_2}=\Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{Z}(x)\pmb{Z}^{\top}(x) \Big)^{-1} \Big(\frac{1}{n_2}\sum_{x\in{s_2}}Y(x)\pmb{Z}(x)\Big)
\end{equation}

The individual predictions can then be calculated as $\hat{Y}(x)=\pmb{Z}^{\top}(x)\hat{\pmb{\beta}}_{s_2}$ and the empirical model residuals, which are only available at all sample locations $x \in s_2$, are calculated as $\hat{R}(x)=Y(x)-\hat{Y}(x)$. Unless stated otherwise, \pkg{forestinventory} only uses internal models to calculate estimates. This means that the model fit, i.e., $\hat{\pmb{\beta}}_{s_2}$, is derived from the current inventory data that are passed to the \code{twophase()} and \code{threephase()} functions.  While virtually all inventorists fit their models using the current inventory data, sometimes there is reason to use formulas derived from external models where the sample used to train the model is assumed to be taken from an independent source \citep{massey2015a}. However, this usually occurs when using a model other than the OLS regression model and is beyond the scope of the package at this time.\par

The package provides the calculation of point estimates under exhaustive (EX) and non-exhaustive (NEX) use of the auxiliary information, which means to respectively apply $\hat{\pmb{\beta}}_{s_2}$ to $\bar{\pmb{Z}}$, i.e., the exact spatial mean of $\pmb{Z}(x)$, or to $\hat{\bar{\pmb{Z}}}$, i.e., an estimate of the spatial mean of $\pmb{Z}(x)$:


\begin{subequations}\label{eq:pointest_2p_reg}
\begin{align}
  \hat{Y}_{reg2p,EX} & =\bar{\pmb{Z}}^{\top}\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_ex}\\
  \hat{Y}_{reg2p,NEX} & =\hat{\bar{\pmb{Z}}}^{\top}\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_nex}
\end{align}
\end{subequations}

Note that for internal linear models containing intercept terms, the mean of the empirical residuals $\frac{1}{n_2}\sum_{x\in{s_2}}\hat{R}(x)$ is zero by construction (zero mean residual property) which is why it does not appear in the point estimate. More explanation about how to obain the auxiliary means is given in the next subsection.

The \pkg{forestinventory} package implements two kinds of variances for each of these point estimates: the g-weight formulation that accounts for the fact that our model is in fact internal, and the external variance formulation that assumes a true external regression model and thus neglects the uncertainty in the regression coefficients \citep{mandallaz2016}.

The g-weight formulation is

\begin{subequations}\label{eq:gw_var_2p_reg}
\begin{align}
  \hat{\var}(\hat{Y}_{reg2p,EX}) & :=\bar{\pmb{Z}}^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\bar{\pmb{Z}} \label{eq:gw_var_2p_reg_ex}\\
  \hat{\var}(\hat{Y}_{reg2p,NEX}) & :=
  \hat{\bar{\pmb{Z}}}^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\hat{\bar{\pmb{Z}}}
  + \hat{\pmb{\beta}}_{s_2}^{\top}\hat{\pmb{\Sigma}}_{\hat{\bar{\pmb{Z}}}}\hat{\pmb{\beta}}_{s_2} \label{eq:gw_var_2p_reg_nex}
\end{align}
\end{subequations}

where the g-weight variance-covariance matrix of $\hat{\pmb{\beta}}_{s_2}$ is calculated as

\begin{equation}\label{eq:estvarmatrix}
  \hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}:=\Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{Z}(x)\pmb{Z}^{\top}(x) \Big)^{-1}
  \Big(\frac{1}{n_2^2}\sum_{x\in{s_2}}\hat{R}^2(x)\pmb{Z}(x)\pmb{Z}^{\top}(x)\Big)
  \Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{Z}(x)\pmb{Z}^{\top}(x) \Big)^{-1}
\end{equation}

and the uncertainty caused by using the $s_1$ sample to estimate $\bar{\pmb{Z}}$ by $\hat{\bar{\pmb{Z}}}$ is accounted for by the variance-covariance matrix of the auxiliary vector $\hat{\bar{\pmb{Z}}}$
\begin{equation}\label{estvarcovaux}
\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}}=
\frac{1}{n_{1}(n_{1}-1)}\sum_{x\in{s_{1}}}
(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}})(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}})^{\top}
\end{equation}

The external variance formulation for linear regression models is

\begin{subequations}\label{eq:varexternal_2p_reg}
\begin{align}
  \hat{\var}_{ext}(\hat{Y}_{reg2p,EX}) & = \frac{1}{n_2}\hat{\var}_{s_2}(\hat{R}(x)) \label{eq:varexternal_2p_reg_ex} \\
  \hat{\var}_{ext}(\hat{Y}_{reg2p,NEX}) & = \frac{1}{n_1}\hat{\var}_{s_1}(\hat{Y}(x)) + \frac{1}{n_2}\hat{\var}_{s_2}(\hat{R}(x)) \nonumber  \label{eq:varexternal_2p_reg_nex}
\end{align}
\end{subequations}
where $\hat{\var}_{s_2}$ and $\hat{\var}_{s_1}$ indicate taking the sample variance over $s_2$ and $s_1$ respectively.

Note that when applied to internal linear regression models, the external variance is asymptotically unbiased and usually slightly smaller than the g-weight variance, where the uncertainty of the regression coefficients is accounted for by the variance-covariance matrix (Eq. \ref{eq:estvarmatrix}).  The external variances are provided in the package \pkg{forestinventory} in case the user wants to compare linear models to another model type where no g-weight formulation is possible, as is the case with non-parametric models like kNN.

\subsubsection{Calculation of explanatory variables}

We will now draw our attention to the calculation of the explanatory variables from the auxiliary data for both the non-exhaustive and exhaustive cases. Fig. \ref{fig:exh_nexh_and_boundweights_b} depicts how the non-exhaustive case often looks like in practice: a regular terrestrial grid $s_2$ is given by a terrestrial inventory (the points surrounded by dotted circles) and densified to a larger sample $s_1$ (the points). For every point $x$, each explanatory variable in the vector $\pmb{Z}(x)=(z(x)_1, z(x)_2,...,z(x)_p)^{\top}$ is calculated using a defined spatial extent of auxiliary information around that point called the support (the dark green square tiles). We emphasize that the value of the explanatory variables for $\pmb{Z}(x)$ are associated with the sample point whereas the support is the spatial extent of the auxiliary information used to calculate those values. So far this is in perfect agreement with the presented theory of the non-exhaustive estimator, except for using regular grids rather than randomly placed sample points. The \pkg{forestinventory} package calculates the empirical mean of $\pmb{Z}(x)$ automatically from the input data frame using $\hat{\bar{\pmb{Z}}}=\frac{1}{n_{1}}\sum_{x\in{s_{1}}}\pmb{Z}(x)$.\par

The exhaustive case requires a closer look. In the infinite population approach, $\pmb{Z}(x)$ refers to the sample point $x$ and not the area around it. Deriving the exact spatial mean, $\bar{\pmb{Z}}=\frac{1}{\lambda(F)}\int_{F} \pmb{Z}(x)dx= (\frac{1}{\lambda(F)}\int_{F} z_1(x)dx, ..., \frac{1}{\lambda(F)}\int_{F} z_p(x)dx)^{\top}$, implies that we need to calculate the spatial mean of each component of $\pmb{Z}(x)$ using all possible points in $F$. This is much like the situation we had with calculating the mean of the local density surface for $Y(x)$ in that we need to find the mean of $\pmb{Z}(x)$ over an infinite number of sample points (i.e., $n_1=\infty$). Although it is practically infeasible to assess $\pmb{Z}(x)$ for every $x$, there are few cases where the exact mean can in fact be precisely calculated. The first case is when the explanatory variables are provided by polygon layers (e.g., map of development stages). In this case, one can calculate the exact mean as the area-weighted average of each categorical variable. The second case is when the exact mean can be calculated in one step, e.g., taking the mean of all height pixels of a raster canopy height model will exactly equal the mean calculated by the use of an infinite number of supports \citep{mandallaz2013b}. However, for most types of explanatory variables, e.g. order statistics such as maximum or median canopy height in the spatial extent, this approach will fail.  For example, the mean of the maximum pixel heights across all supports is clearly not equal to the global maximum pixel height across the entire area.  In such cases, we will try to get an approximation of $\bar{\pmb{Z}}$ that is only negligibly different. \par

One implementation to approximate the exact mean $\bar{\pmb{Z}}$ is shown in Fig. \ref{fig:exh_nexh_and_boundweights_a}, where the spatial arrangement of the supports (the dark green tiles) are tessellated to form a perfect partition over the inventory area in order for all of the wall-to-wall auxiliary information to be exploited. Is has to be noted that this setup would allow for a perfect calculation of the exact mean $\bar{\pmb{Z}}$ in the finite population approach, i.e., deriving $\pmb{Z}(x)$ for the finite population of supports that are considered the sampling units. While in the infinite population approach this implementation probably does not produce the true exact mean $\bar{\pmb{Z}}$, $n_1$ is still expected to be reasonably large for the difference to be considered negligible as long as the size of the supports are not unreasonably large. However, the perfect tessellation implementation can also impose drawbacks. One is that a perfect tessellation by the supports strongly depends on the distance between the sample locations of $s_1$ and the support size. Since in practice the support size should ideally be chosen to achieve a best possible explanatory power of the regression model \citep{hill2018} a perfect tessellation might often not be feasible. In the infinite population frame, the supports are allowed to overlap if this seems necessary to acquire a sufficiently large sample $n_1$ to get a negligibly close approximation of $\bar{\pmb{Z}}$. With this respect, the infinite population approach provides more flexibility than the finite approach. 

\begin{figure}[htb]
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
    \resizebox{0.8\hsize}{!}{\includegraphics{fig/boundaryweight_graphic(left).eps}}%
		\caption{} \label{fig:exh_nexh_and_boundweights_a}
		\end{subfigure}
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
   \resizebox{0.8\hsize}{!}{\includegraphics{fig/boundaryweight_graphic(right).eps}}%
		\caption{} \label{fig:exh_nexh_and_boundweights_b}
	\end{subfigure}
\caption{Concept of (a) exhaustive and (b) non-exhaustive calculation of explanatory variables including boundary adjustment at the support level. Auxiliary data are in both cases available over the entire inventory area marked by the large rectangle. A vector of explanatory variables $\pmb{Z}(x)$ is calculated within the supports (small squares)  at each sample location $x$ (points) that falls into the forest area (green underlying polygon).}
\label{fig:exh_nexh_bw}
\end{figure}

\subsubsection{Boundary adjustment}

An extension to the so-far published estimators by Mandallaz is the consideration of a boundary adjustment. In forest inventories, the sample is often restricted to those sample locations located within the forest area. In case a consistent forest definition can be applied to both the $s_2$ and $s_1$ sample (e.g., by a polygon forest mask layer), it might be desired to restrict the calculation of the explanatory variables to the forest area within the given support (see Fig. \ref{fig:exh_nexh_bw}). This method was suggested in \citet{mandallaz2013b} and led to an improvement in estimation precision. In order to ensure an unbiased calculation of either $\hat{\bar{\pmb{Z}}}$ or $\bar{\pmb{Z}}$, the respective means have then to be calculated as the weighted mean (Eq. \ref{eq:wmeanZ}) where the weight $w(x)$ is equal to the percentage of forested area within the support of sample location $x$.

\begin{equation}\label{eq:wmeanZ}
  \hat{\bar{\pmb{Z}}}=\frac{\sum_{x\in{s_1}}w(x)\pmb{Z}(x)}{\sum_{x\in{s_1}}w(x)}
\end{equation}


% --------------------------- %
\subsubsection{Restricting the inventory domain to forested area}

In some national forest inventories it has been common to sample information over the entire country, i.e., also at places outside forest even including areas such as high mountain sides where no trees can actually grow. This is caused by the fact that in order to calculate totals by multiplying the estimated density (e.g., timber volume per hectare) with the area value of the inventory domain, the area of a country is well known, whereas the precise area of the forest is often much harder to determine. In \citet{mandallaz2014} it is demonstrated that by doing so, one usually inflates the sample by a large number of zeros for the target variable (i.e., at sample locations outside forest). It has been mathematically shown that by this procedure, the coefficient of determination (R$^2$) of the regression model can be overoptimistic as the zeros are easy to predict. This is particularly the case if the occurence of zeros correlate with an explanatory variable, such as the elevation above sea level. Furthermore, \citet{mandallaz2014} showed that this procedure is inefficient as it inflates the estimated variance. In order to mitigate this effect, a solution is to filter out most of the non-forested areas where one can certainly assume that no forest exists.


% --------------------------- %
\subsubsection{Application}

To demonstrate the use of the global two-phase estimators, we will use the \code{grisons} data set that comes with installing the package from the CRAN repository. The data set contains data from a simple (i.e., non-cluster) two-phase forest inventory conducted in 2007 that was used in \citet{mandallaz2013b} as a case study. The $s_1$ sample is comprised of 306 sample locations arranged on a systematic grid containing auxiliary information in the form of airborne laserscanning (LiDAR) canopy height metrics (\code{mean}, \code{stddev}, \code{max}, \code{q75}). For a systematic subsample of 67 ($s_2$ sample), terrestrial information of the timber volume per hectare (\code{tvol}) on the sample plot level is provided from a terrestrial survey. We can load \pkg{forestinventory} and examine the \code{grisons} data set in the \proglang{R} environment as follows:

\begin{small}
<<eval=FALSE>>=
library("forestinventory")
data("grisons", package = "forestinventory")
head(grisons)
@
\end{small}

\begin{small}
<<eval=TRUE, echo=FALSE>>=
library("forestinventory")
set.seed(666)
g.temp<- grisons[sample(1:306,10),c(1,3,4,5,6,7,8,9)]
 g.temp[,c(2,3,4,5,6,8)]<- round(g.temp[,c(2,3,4,5,6,8)], digits = 2)
print(head(g.temp, n = 10), row.names = seq(1:10))
rm(g.temp)
@
\end{small}

Estimates can be made using the \code{onephase()}, \code{twophase()} or \code{threephase()} functions. The data frame inputted to these functions must have the structure where each row corresponds to a unique sample location and the columns specify the attributes associated to that respective sample location. Attributes that are missing, e.g., because they are associated with sample locations that were not selected in the subsample for the subsequent phase, should be designated as \code{NA} and the phase membership is encoded as numeric.

For global two-phase estimation, we have to specify

\begin{itemize}
  \itemsep0em
  \item the regression model (\code{formula}) as specified in the \code{lm}()-function \citep{R}.
  \item the inputted \code{data.frame} containing the inventory information (\code{data}).
  \item the \code{list}-object \code{phase_id} containing: the \code{phase.col} argument identifying the name of the column specifying membership to $s_1$ or $s_2$, and the \code{terrgrid.id} argument specifying which numeric value indicates $s_2$ membership in that column. Note that \pkg{forestinventory} implicitly assumes that all rows not indcated as $s_2$ belong to the $s_1$ phase.
  \item the name of the column containing the weights $w(x)$ of the boundary adjustments (optional).
\end{itemize}

The non-exhaustive estimator with boundary weight adjustment can thus be applied as follows:

\begin{small}
<<>>=
reg2p_nex <- twophase(formula = tvol ~ mean + stddev + max + q75, data = grisons, 
  phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
  boundary_weights = "boundary_weights")
@
\end{small}

The \code{twophase()} function creates an \code{S3} object of class \code{"twophase"} with subclass \code{"global"}. A readable summary of the estimation results can be obtained by passing this object to the \code{summary()} function, which automatically interprets what type of estimator was used and returns pertinent information such as the regression model formula, the point estimate (\code{estimate}), the g-weight and external variance (\code{g_variance} and \code{ext_variance}) as well as the sample sizes and the model R$^2$:

\begin{small}
<<>>=
summary(reg2p_nex)
@
\end{small}

% \begin{Schunk}
% \begin{Sinput}
% Two-Phase global estimation
%  
% Call: 
% twophase(formula = tvol ~ mean + stddev + max + q75, data = grisons, 
%     phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2), 
%     boundary_weights = "boundary_weights")
% 
% Method used:
% Non-exhaustive global estimator
%  
% Regression Model:
% tvol ~ mean + stddev + max + q75
% 
% Estimation results:
%  estimate ext_variance g_variance  n1 n2 r.squared
%  383.5354      279.954   271.5057 306 67 0.6428771
% 
% 'boundary_weight'- option was used to calculate weighted means of auxiliary variables
% \end{Sinput}
% \end{Schunk}

For practical use, one should normally always prefer the g-weight variance over the external variance. This is because when we use internal models, the regression coefficients actually depend on the terrestrial sample realized by the sampling design. In contrast to the external variance, the g-weight variance accounts for this sampling variability which results in more reliable point and variance estimates and also enjoys better statistical calibration properties (g-weights). The external and g-weight variances are asymptotically equivalent but the external variance is really only included here in case the user wants to compare to another estimator where no g-weight variance exists.

The exhaustive estimator can be applied by additionally passing a vector containing the exact means of the explanatory variables, i.e., $\bar{\pmb{Z}}$, to the optional argument \code{exhaustive}. This vector must be calculated beforehand in such a way that any desired boundary adjustment has already been applied. Note that the vector input to \code{exhaustive} must be in the same order that the \code{lm()}-function processes a \code{formula} object including the intercept term whose exact mean will always be 1. Particular caution must be taken if categorical variables are present because the \code{lm()}-function, which is internally used to set up the design-matrix, automatically creates dummy variables with one of the categories used as a reference. Using our \code{grisons} example, the correct order can always be extracted by the following \proglang{R}-code:


\begin{small}
<<eval=FALSE>>=
colnames(lm(formula = tvol ~ mean + stddev + max + q75, data = grisons, 
  x = TRUE)$x)
@
\end{small}

The exhaustive estimator can be applied after defining the vector of exact means $\bar{\pmb{Z}}$ taken from \citet{mandallaz2013b}, denoted as \code{true.means.Z}:

\begin{small}
<<>>=
true.means.Z <- c(1, 11.39, 8.84, 32.68, 18.03)

reg2p_ex <- twophase(formula = tvol ~ mean + stddev + max + q75,
  data = grisons,
  phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
  exhaustive = true.means.Z)
@
\end{small}

An alternative way to look at the estimation results without using the \code{summary()} is to query \code{reg2p_ex} directly:
\begin{small}
<<>>=
reg2p_ex$estimation
@
\end{small}
Note that both variances of the exhaustive estimation are smaller than those of the non-exhaustive estimation. This is essentially because we eliminated one component of uncertainty by substituting the estimated means of the explanatory variables $\hat{\bar{\pmb{Z}}}$ by their exact means $\bar{\pmb{Z}}$.


%--------------------------------------------------------------------------------------------------%
% ################################################################################################ %
%--------------------------------------------------------------------------------------------------%

\subsection{Small area estimators}
\label{sec:twophase_sae}

\subsubsection{Mathematical background}

The \pkg{forestinventory} package provides three types of small area estimators each of which has an exhaustive and non-exhaustive form. We will use a different nomenclature for the non-exhaustive case in small area estimation since much of the existing literature shows preference for the label pseudo to indicate that the mean of the explanatory variables within the small area was based on a finite sample. The main idea for all these small area estimators is to calculate the regression coefficient vector $\hat{\pmb{\beta}}_{s_2}$ and its variance-covariance matrix $\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}$ on the entire $s_2$ sample according to Eq. \ref{normequ_simple} and \ref{eq:estvarmatrix}, and subsequently use that to make predictions for sample locations restricted to small area $G$.\par

%----------------------------------------------- %
% \textbf{Small and Pseudo Small Area Estimator}\par

We first introduce the small area estimator (SMALL), which uses exhaustively computed explanatory variables, and its non-exhaustive version, the pseudo small area estimator (PSMALL). 

\begin{subequations}\label{eq:pest_2p_small_psmall}
\begin{align}
  \hat{Y}_{G,SMALL,2p} & =\bar{\pmb{Z}}_G^{\top}\hat{\pmb{\beta}}_{s_2} + \frac{1}{n_{2,G}}\hat{R}(x)  \label{eq:pointest_2p_small} \\
  \hat{Y}_{G,PSMALL,2p} & =\hat{\bar{\pmb{Z}}}_G^{\top}\hat{\pmb{\beta}}_{s_2} + \frac{1}{n_{2,G}}\hat{R}(x) \label{eq:pepsmall}
\end{align}
\end{subequations}

In the equations for the point estimates (Eq. \ref{eq:pointest_2p_small} and \ref{eq:pepsmall}), we see that the globally derived regression coefficients are applied to the exhaustively or non-exhaustively calculated means of the explanatory variables ($\bar{\pmb{Z}}_G$, $\hat{\bar{\pmb{Z}}}_G$) which are now only based on the first-phase sample $s_{1,G}$ located within small area $G$. A potential bias of the regression model predictions in the small area $G$, due to fitting the regression model with data also outside of $G$, is then corrected by adding the mean of the empirical model residuals in $G$. This is called the bias or residual correction term.

The package provides the g-weight variance for SMALL and PSMALL respectively (Eq. \ref{eq:var_2p_reg_small}, \ref{eq:var_2p_reg_psmall}) as well as the  external variance (Eq. \ref{eq:varext_2p_reg_small}, \ref{eq:varext_2p_reg_psmall}). Again note that all components are restricted to those available at the sample locations in the small area ($s_{1,G}$ and $s_{2,G}$), with exception of the regression coefficient components $\hat{\pmb{\beta}}_{s_2}$ and $\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}$.


\begin{subequations}\label{eq:var_2p_small_psmall}
\begin{align}
  \hat{\var}(\hat{Y}_{G,SMALL,2p}) & := \bar{\pmb{Z}}_G^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\bar{\pmb{Z}}_G
    + \frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{R}(x))  \label{eq:var_2p_reg_small} \\
  \hat{\var}(\hat{Y}_{G,PSMALL,2p}) & := \hat{\bar{\pmb{Z}}}_G^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\hat{\bar{\pmb{Z}}}_G
  + \hat{\pmb{\beta}}_{s_2}^{\top}\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}_G}\hat{\pmb{\beta}}_{s_2}
  + \frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{R}(x))  \label{eq:var_2p_reg_psmall}
\end{align}
\end{subequations}

\begin{subequations}\label{eq:varext_2p_small_psmall}
\begin{align}
  \hat{\var}_{ext}(\hat{Y}_{G,SMALL,2p}) & := \frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{R}(x))  \label{eq:varext_2p_reg_small} \\
  \hat{\var}_{ext}(\hat{Y}_{G,PSMALL,2p}) & := \frac{1}{n_{1,G}}\hat{\var}_{s_{2,G}}(Y(x)) + \Big(1-\frac{n_{2,G}}{n_{1,G}}\Big)\frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{R}(x)) \label{eq:varext_2p_reg_psmall}
\end{align}
\end{subequations}
where $\hat{\var}_{s_{2,G}}$ indicates taking the sample variance over $s_{2,G}$. If boundary adjustment is applied, the simple mean of the explanatory variable vector over the small area $\hat{\bar{\pmb{Z}}}_G=\frac{1}{n_{1,G}}\sum_{x \in s_{1,G}}\pmb{Z}(x)$ is replaced by its weighted version $\hat{\bar{\pmb{Z}}}_G=\frac{\sum_{x\in{s_{1,G}}}w(x)\pmb{Z}(x)}{\sum_{x\in{s_{1,G}}}w(x)}$, and likewise for exhaustively used auxiliary information.



%------------------------------------------------------------- %
% \textbf{Synthetic and Pseudo Synthetic Estimator}\par

The synthetic estimator (SYNTH) and pseudo synthetic estimator (PSYNTH) are commonly applied when no terrestrial sample is available within the small area $G$ (i.e., $n_{2,G}=0$). In this case, the point estimates (Eq. \ref{eq:pointest_2p_reg_synth} and \ref{eq:pointest_2p_reg_psynth}) are based only on the predictions generated by applying the globally derived regression model to the auxiliary vectors $\bar{\pmb{Z}}_G$ and $\hat{\bar{\pmb{Z}}}_G$ respectively. However, the bias correction using the observed residuals $\hat{R}(x)$ is not applied as was the case in the small and pseudo small area estimator (Eq. \ref{eq:pointest_2p_small} and \ref{eq:pepsmall}). Thus, the (pseudo) synthetic estimator has a potentially unobservable design-based bias. Also note that the residual variation can no longer be considered in the g-weight variance (Eq. \ref{eq:var_2p_reg_synth} and \ref{eq:var_2p_reg_psynth}). Therefore, the synthetic estimators will usually have a smaller variance than estimators incorporating the regression model uncertainties, but at the cost of a potential bias. Due to the absence of available residuals in $G$, there is also no external variance form for the synthetic and pseudo synthetic estimator.

% Left out for simplicity reasons in article, maybe include in Diss:
% However, this assumption is unlikely to be fullfilled in practice resulting in a potentially unobservable design-based bias equal to $-\frac{1}{\lambda(G)}\int_G R(x)$. 

\begin{subequations}\label{eq:pest_2p_synth_psynth}
\begin{align}
  \hat{Y}_{G,SYNTH,2p} & =\bar{\pmb{Z}}_G^{\top}\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_synth} \\
  \hat{Y}_{G,PSYNTH,2p} & =\hat{\bar{\pmb{Z}}}_G^{\top}\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_psynth} \\
  \hat{\var}(\hat{Y}_{G,SYNTH,2p}) & = \bar{\pmb{Z}}_G^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\bar{\pmb{Z}}_G \label{eq:var_2p_reg_synth} \\
  \hat{\var}(\hat{Y}_{G,PSYNTH,2p}) & = \hat{\bar{\pmb{Z}}}_G^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\hat{\bar{\pmb{Z}}}_G
  + \hat{\pmb{\beta}}_{s_2}^{\top}\hat{\pmb{\Sigma}}_{\hat{\bar{\pmb{Z}}}_G}\hat{\pmb{\beta}}_{s_2}  \label{eq:var_2p_reg_psynth}
\end{align}
\end{subequations}

where the variance-covariance matrix of the auxiliary vector $\hat{\bar{\pmb{Z}}}_G$ is estimated by
\begin{equation}\label{estvarcovaux_G}
\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}_{G}}=
\frac{1}{n_{1,G}(n_{1,G}-1)}\sum_{x\in{s_{1,G}}}
(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}}_{G})(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}}_{G})^{\top}
\end{equation}

%------------------------------------------------------------- %
% \textbf{Extended Synthetic and Extended Pseudo Synthetic Estimator}\par

The synthetic estimators, SYNTH and PSYNTH, have attractively compact formulas but come with the downside of potential bias in their point estimates which can make the variances seem deceptively optimistic. The SMALL and PSMALL estimators overcome this issue by using a bias correction term, i.e., $\frac{1}{n_{2,G}}\sum_{x \in s_{2,G}}\hat{R}(x)$. The motivation behind the extended synthetic and extended pseudo synthetic estimator (EXTSYNTH and EXTPSYNTH) is to use the same mathematically elegant formulas of the (pseudo) synthetic estimators while ensuring that the mean of the empirical prediction model residuals in the entire area $F$ and the small area $G$ are by construction both zero at the same time. This is accomplished by extending the vector of auxiliary information $\pmb{Z}(x)$ by a binary categorical indicator variable $I_G(x)$ which takes the value 1 if the sample location $x$ lies inside the target small area $G$ and is otherwise set to 0. Recalling that linear models fitted using OLS have zero mean residual property by construction also if categorical variables are used, this leads to unbiased point estimates. The new extended auxiliary vector thus becomes $\pmb{\mathbb{Z}}^{\top}(x)=(\pmb{Z}^{\top}(x),I^{\top}_G(x))$ and can be used to replace its non-extended counterpart $\pmb{Z}^{\top}(x)$ whereever it is used in Eq. \ref{eq:pest_2p_synth_psynth} and \ref{estvarcovaux_G}. Note that the package functions internally extend the data set by the indicator variable if the EXTSYNTH or EXTPSYNTH estimator is called.

Not every equation needs to be re-written here, but to give an example of the notational change, the regression coefficient under extended model approach becomes

\begin{equation}\label{ext_normequ_simple}
  \hat{\pmb{\theta}}_{s_2}=\Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{\mathbb{Z}}(x)\pmb{\mathbb{Z}}^{\top}(x) \Big)^{-1} \Big(\frac{1}{n_2}\sum_{x\in{s_2}}Y(x)\pmb{\mathbb{Z}}(x)\Big)
\end{equation}

The point estimates and their g-weight variances can then be re-written as

\begin{subequations}\label{eq:pest_2p_extsynth_extpsynth}
\begin{align}
\hat{Y}_{G,EXTSYNTH,2p} & = \bar{\pmb{\mathbb{Z}}}^{\top}_{G}\hat{\pmb{\theta}}_{s_2} \label{eq:pointest_2p_extsynth} \\
\hat{Y}_{G,EXTPSYNTH,2p} & =\hat{\bar{\pmb{\mathbb{Z}}}}_{G}^{\top}\hat{\pmb{\theta}}_{s_2} \label{eq:pointest_2p_extsynth} \\
\hat{\var}(\hat{Y}_{G,EXTSYNTH,2p}) & = \bar{\pmb{\mathbb{Z}}}^{\top}_{G}\hat{\pmb{\Sigma}}_{\hat{\pmb{\theta}}_{s_2}}\bar{\pmb{\mathbb{Z}}}_{G} \label{eq:var_2p_extsynth} \\
\hat{\var}(\hat{Y}_{G,EXTPSYNTH,2p})& =
\hat{\bar{\pmb{\mathbb{Z}}}}_{G}^{\top}\hat{\pmb{\Sigma}}_{\hat{\pmb{\theta}}_{s_2}}
\hat{\bar{\pmb{\mathbb{Z}}}}_{G}
+ \hat{\pmb{\theta}}^{\top}_{s_2}\hat{\pmb{\Sigma}}_{\hat{\bar{\pmb{\mathbb{Z}}}}_{G}}\hat{\pmb{\theta}}_{s_2} \label{eq:var_2p_extpsynth}
\end{align}
\end{subequations}

While the formulas look similar to the synthetic estimators, note that a decomposition of $\hat{\pmb{\theta}}_{s_2}$ reveals that the residual correction term is now included in the regression coefficient $\hat{\pmb{\theta}}_{s_2}$ \citep{mandallaz2016} and thus the estimates are asymptotically design-unbiased.

The package also provides the external variance for both the extended synthetic and extended pseudo synthetic estimator. Note that neither the extended model approach nor external variance estimates are possible in the absence of terrestrial samples and thus model residuals in $G$, which is precisely when one must rely on the (pseudo) synthetic estimates. The external variance forms of EXTSYNTH and EXTPSYNTH are

\begin{subequations}\label{eq:ext_varexternal_2p_extsynth}
\begin{align}
  \hat{\var}_{ext}(\hat{Y}_{G,EXTSYNTH,2p}) & = \frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{\mathbb{R}}(x)) \label{eq:ext_varexternal_2p_extsynth} \\
  \hat{\var}_{ext}(\hat{Y}_{G,EXTPSYNTH,2p}) & = \frac{1}{n_{1,G}}\hat{\var}_{s_{2,G}}(Y(x)) + \Big(1-\frac{n_{2,G}}{n_{1,G}}\Big)\frac{1}{n_{2,G}}\hat{\var}_{s_{2_G}}(\hat{\mathbb{R}}(x)) \label{eq:ext_varexternal_2p_extpsynth}
\end{align}
\end{subequations}
where $\hat{\mathbb{R}}(x)$ are the empirical residuals under the extended auxiliary vector.

To summarize, the synthetic estimators SYNTH and PSYNTH can be applied whether terrestrial inventory sample is found in the small area or not, but has a deceptively small g-weight variance due to its potential bias.  When terrestrial sample is observed in the small area, we can produce (asymptotically) design-unbiased estimates and variances using either SMALL or PSMALL which remove this bias explicitly with a mean residual term, or more elegantly with EXTSYNTH or EXTPSYNTH which simply use the same synthetic formulas while including an indicator variable for the small area in the model formula to remove the bias by construction in OLS.


%------------------------------------------------------------- %
\subsubsection{Application}

Small area estimates in the \pkg{forestinventory} package can be applied by specifying the optional argument \code{small_area}. The input data set has to include an additional column of class \code{factor} that describes the small area membership of the sample location represented by that row. The argument \code{small_area} requires a \code{list}-object that comprises

\begin{itemize}
  \itemsep0em
  \item the name of the column specifiying the small area of each observation (\code{sa.col}).
  \item a vector specifying the small area(s) for which estimations are desired (\code{areas}).
  \item the argument \code{unbiased} that controls which of the three available estimators is applied.
\end{itemize}

In order to apply the pseudo small area estimator (PSMALL) with boundary adjustment, we set \code{unbiased=TRUE} as well as the optional argument \code{psmall=TRUE}:
\begin{small}
<<>>=
psmall_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, 
  data = grisons, phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
  small_area = list(sa.col = "smallarea", areas = c("A", "B"),
  unbiased = TRUE), psmall = TRUE, boundary_weights = "boundary_weights")
@
\end{small}

\begin{small}
<<>>=
summary(psmall_2p)
@
\end{small}

The small area functions all return an \code{S3} object of class \code{"twophase"} with subclass \code{"smallarea"}. In addition to global estimation, the \code{estimation} object now comprises the estimates and variances for all small areas (column \code{area}). We can view the sample sizes by looking into the object itself
\begin{small}
<<>>=
psmall_2p$samplesizes
@
\end{small}

The extended pseudo synthetic estimator (EXTPSYNTH) can be applied by setting \code{unbiased=TRUE} and leaving the optional argument \code{psmall} to its default value of \code{FALSE}:


\begin{small}
<<>>=
extpsynth_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, 
  data = grisons, phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
  small_area = list(sa.col = "smallarea", areas = c("A", "B"),
  unbiased = TRUE), boundary_weights = "boundary_weights")
extpsynth_2p$estimation
@
\end{small}

The \pkg{forestinventory} package automatically includes the indicator variable for the small area behind the scenes so there is no need for the user to implement it. Notice that the $R^2$s (\code{r.squared}) under the EXTPSYNTH estimator vary between the small areas, while they are identical under the PSMALL estimator. This is because under the EXTPSYNTH estimator, the regression model is recalculated for each small area estimation after adding the indicator variable for the respective small area in the globally derived design matrix. In case of the PSMALL estimator, the regression model stays the same for each small area estimation. Although the results of both estimators should always be close to each other, we recommend applying both estimators and compare the results afterwards in order to reveal unsuspected patterns in the data, particularly in the case of cluster sampling (see Section \ref{sec:speccas_and_scen}).\par

Setting the argument \code{unbiased=FALSE} applies the pseudo synthetic estimator to the selected small areas. Note that in the \code{grisons} data set, all small areas possess much more than the suggested minimum number of terrestrial observations (a rule of thumb is that $n_{2,G} \geq 6$) required to produce reliable design-unbiased estimates. Hence, choosing to use PSYNTH is probably not desireable and is just applied here for demonstration purposes. In this case the residual correction will not be applied.


\begin{small}
<<>>=
psynth_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, 
  data = grisons, phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
  small_area = list(sa.col = "smallarea", areas = c("A", "B"),
  unbiased = FALSE), boundary_weights = "boundary_weights")
@
\end{small}

\begin{small}
<<>>=
psynth_2p$estimation
@
\end{small}

We see here that the PSYNTH variances are almost only half the variances of the PSMALL and EXTPSYNTH estimator. However, PSMALL and EXTPSYNTH are design unbiased and their variances reflect the fact that they account for potential bias of the regression model predictions. The g-weight variance of PSYNTH completely neglects a potential bias and as a result risks severely overstating the estimation precision.\par

The exhaustive versions of the small area estimators (Eq. \ref{eq:pointest_2p_small}, \ref{eq:var_2p_reg_small}, \ref{eq:varext_2p_reg_small}, \ref{eq:pointest_2p_reg_synth}, \ref{eq:var_2p_reg_synth}) are specified via the optional argument \code{exhaustive}. Its application requires that we know the exact means of all explanatory variables within the small area(s) of interest. In contrast to the global estimators, the exact means have now to be delivered in the form of a \code{data.frame}, where each row corresponds to a small area, and each column specifies the exact mean of the respective explanatory variable. Note that likewise the case of global estimation, the order of the explanatory variables in the data frame has to match the order in which they appear in the design matrix defined by the \code{lm()}-function in \proglang{R}. In order to tell \proglang{R} which row describes which small area, the row names have to match the respective names of the small areas specified in the \code{areas} argument.

For the \code{grisons} data set, the exact means of the explanatory variables for the small areas used in \citet{mandallaz2013b} are thus defined by
\begin{small}
<<eval=FALSE>>=
colnames(lm(formula = tvol ~ mean + stddev + max + q75, data = grisons, 
  x = TRUE)$x)
@
\end{small}
\begin{small}
<<>>=
true.means.Z.G <- data.frame(Intercept = rep(1, 4),
  mean = c(12.85, 12.21, 9.33, 10.45),
  stddev = c(9.31, 9.47, 7.90, 8.36),
  max = c(34.92, 35.36, 28.81, 30.22),
  q75 = c(19.77, 19.16, 15.40, 16.91))
rownames(true.means.Z.G) <- c("A", "B", "C", "D")
@
\end{small}
\begin{small}
<<>>=
true.means.Z.G
@
\end{small}

The extended synthetic estimator (EXTSYNTH) can then be applied by
\begin{small}
<<>>=
extsynth_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, 
  data = grisons, phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
  small_area = list(sa.col ="smallarea", areas = c("A", "B"),
  unbiased = TRUE), exhaustive = true.means.Z.G)
@
\end{small}

\begin{small}
<<>>=
extsynth_2p$estimation
@
\end{small}

Just as in the global case, we see that the variance has again been significantly decreased by substituting the exact auxiliary means and both first phase sample sizes are now infinity. Note that the function extracts the required exact means for small area \code{"A"} and \code{"B"} from the complete set of exact means defined in \code{true.means.Z.G}.

\newpage