% !Rnw root = JStatSoft_forestinventory_master.Rnw

\section{Two-phase Estimators and their Application}
\label{sec:twophase_and_appl}


% ---------------------------------------------------------------------------- %
\subsection{Global Estimators}
\label{sec:twophase_globest}

\subsubsection{Mathematical Background}

The vector of regression coefficients of the OLS regression model is found by using the following solution to the sample-based normal equation:

\begin{equation}\label{normequ_simple}
  \hat{\pmb{\beta}}_{s_2}=\Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{Z}(x)\pmb{Z}^t(x) \Big)^{-1} \Big(\frac{1}{n_2}\sum_{x\in{s_2}}Y(x)\pmb{Z}(x)\Big)
\end{equation}

The individual predictions can then be calculated as $\hat{Y}(x)=\pmb{Z}^t(x)\hat{\pmb{\beta}}_{s_2}$ and the empirical model residuals, which are only available at all sample locations $x \in s_2$, are calculated as $\hat{R}(x)=Y(x)-\hat{Y}(x)$. Unless stated otherwise, \pkg{forestinventory} only uses \textit{internal models} to calculate estimates. This means that the model fit, i.e. $\hat{\pmb{\beta}}_{s_2}$, is derived from the current inventory data that are passed to the \code{twophase()} and \code{threephase()} functions.  While virtually all inventorists fit their models using the current inventory data, sometimes there is reason to use formulas derived from external models where the sample used to train the model is assumed to be taken from an independent source \citep{massey2015a}. However, this usually occurs when using a model other than the OLS regression model and is beyond the scope of the package at this time.\par

The package provides the calculation of \textbf{point estimates} under exhaustive ($ex$) and non-exhaustive ($nex$) use of the auxiliary information, which means to respectively apply $\hat{\pmb{\beta}}_{s_2}$ to $\bar{\pmb{Z}}$, i.e. the \textit{exact} spatial mean of $\pmb{Z}(x)$, or to $\hat{\bar{\pmb{Z}}}$, i.e. an \textit{estimate} of the spatial mean of $\pmb{Z}(x)$:


\begin{subequations}\label{eq:pointest_2p_reg}
\begin{align}
  \hat{Y}_{reg2p,ex} & =\bar{\pmb{Z}}^t\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_ex}\\
  \hat{Y}_{reg2p,nex} & =\hat{\bar{\pmb{Z}}}^t\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_nex}
\end{align}
\end{subequations}

Note that for \textit{internal} linear models the mean of the empirical residuals $\frac{1}{n_2}\sum_{x\in{s_2}}\hat{R}(x)$ is zero by construction (\textit{zero mean residual property}) which is why it does not appear in the point estimate. More explanation about how to obain the auxiliary means is given in the next subsection.

The \pkg{forestinventory} package implements two kinds of variances for each of these point estimates: the \textit{g-weight} formulation that accounts for the fact that our model is in fact \textit{internal}, and the \textit{external variance} formulation that assumes a true external regression model and thus neglects the uncertainty in the regression coefficients \citep{mandallaz2016}.

The \textit{g-weight} formulation is
\begin{subequations}\label{eq:gw_var_2p_reg}
\begin{align}
  \hat{\var}(\hat{Y}_{reg2p,ex}) & :=\bar{\pmb{Z}}^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\bar{\pmb{Z}} \label{eq:gw_var_2p_reg_ex}\\
  \hat{\var}(\hat{Y}_{reg2p,nex}) & :=
  \hat{\bar{\pmb{Z}}}^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\hat{\bar{\pmb{Z}}}
  + \hat{\pmb{\beta}}_{s_2}^t\hat{\pmb{\Sigma}}_{\hat{\bar{\pmb{Z}}}}\hat{\pmb{\beta}}_{s_2} \label{eq:gw_var_2p_reg_nex}
\end{align}
\end{subequations}

where the g-weight variance-covariance matrix of $\hat{\pmb{\beta}}_{s_2}$ is calculated as

\begin{equation}\label{eq:estvarmatrix}
  \hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}:=\Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{Z}(x)\pmb{Z}^t(x) \Big)^{-1}
  \Big(\frac{1}{n_2^2}\sum_{x\in{s_2}}\hat{R}^2(x)\pmb{Z}(x)\pmb{Z}^t(x)\Big)
  \Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{Z}(x)\pmb{Z}^t(x) \Big)^{-1}
\end{equation}

and the uncertainty caused by using the $s_1$ sample to estimate $\bar{\pmb{Z}}$ by $\hat{\bar{\pmb{Z}}}$ is accounted for by the variance-covariance matrix of the auxiliary vector $\hat{\bar{\pmb{Z}}}$
\begin{equation}\label{estvarcovaux}
\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}}=
\frac{1}{n_{1}(n_{1}-1)}\sum_{x\in{s_{1}}}
(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}})(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}})^t
\end{equation}

The \textit{external variance} formulation for linear regression models is

\begin{subequations}\label{eq:varexternal_2p_reg}
\begin{align}
  \hat{\var}_{ext}(\hat{Y}_{reg2p,ex}) & = \frac{1}{n_2}\hat{\var}_{s_2}(\hat{R}(x)) \label{eq:varexternal_2p_reg_ex} \\
  \hat{\var}_{ext}(\hat{Y}_{reg2p,nex}) & = \frac{1}{n_1}\hat{\var}_{s_1}(\hat{Y}(x)) + \frac{1}{n_2}\hat{\var}_{s_2}(\hat{R}(x)) \nonumber  \label{eq:varexternal_2p_reg_nex}
\end{align}
\end{subequations}
where $\hat{\var}_{s_2}$ and $\hat{\var}_{s_1}$ indicate taking the sample variance over $s_2$ and $s_1$ respectively.

Note that when applied to internal linear regression models, the external variance is asymptotically unbiased and usually slightly smaller than the g-weight variance, where the uncertainty of the regression coefficients is accounted for by the variance-covariance matrix (Eq. \ref{eq:estvarmatrix}).  The external variances are provided in the package \pkg{forestinventory} in case the user wants to compare linear models to another model type where no g-weight formulation is possible, as is the case with non-parametric models like kNN.

\subsubsection{Calculation of Explanatory Variables}

We will now draw our attention to the calculation of the explanatory variables from the auxiliary data for both the non-exhaustive and exhaustive case. Figure \ref{fig:exh_nexh_and_boundweights_b} depicts how the \textbf{non-exhaustive} case often looks like in practice: a regular terrestrial grid $s_2$ is given by a terrestrial inventory (the points surrounded by dotted circles in Fig. \ref{fig:exh_nexh_and_boundweights_b}) and densified to a larger sample $s_1$ (the points). For every point $x$, each explanatory variable in the vector $\pmb{Z}(x)=(z(x)_1, z(x)_2,...,z(x)_p)^t$ is calculated using a defined spatial extent of auxiliary information around that point called the \textit{support} (the dark green square tiles). We emphasize that the value of the explanatory variables for $\pmb{Z}(x)$ are associated with the point whereas the support is the spatial extent of the auxiliary information used to calculate those values. So far this is in perfect agreement with the presented theory of the non-exhaustive estimator, except for using regular grids rather than randomly placed sample points. The \pkg{forestinventory} package calculates the empirical mean of $\pmb{Z}(x)$ automatically from the input data frame using $\hat{\bar{\pmb{Z}}}=\frac{1}{n_{1}}\sum_{x\in{s_{1}}}\pmb{Z}(x)$.\par

The \textbf{exhaustive} case requires a closer look. Since being in the infinite population approach, $\pmb{Z}(x)$ again refers to the sample point $x$ and not the area around it. Deriving the \textit{exact} spatial mean, $\bar{\pmb{Z}}=\frac{1}{\lambda(F)}\int_{F} \pmb{Z}(x)dx= (\frac{1}{\lambda(F)}\int_{F} z_1(x)dx, ..., \frac{1}{\lambda(F)}\int_{F} z_p(x)dx)^t$, implies that we need to calculate the spatial means of each component of $\pmb{Z}(x)$ using all possible points in $F$. This is much like the situation we had with calculating the mean of the local density surface for $Y(x)$ in that we need to find the mean of $\pmb{Z}(x)$ over an infinite number of sample points (i.e. $n_1=\infty$). Of course this is practically infeasible, but there are few cases where the exact mean can also be precisely calculated in the infinite population framework. The first case is when the explanatory variables are provided by polygon layers (e.g. map of development stages). In this case, one can calculate the exact mean as the area-weighted average of each categorical variable. The second case is when the exact mean can be calculated in one step, e.g. taking the mean of all height pixels of a raster canopy height model will perfectly equal the mean calculated by the use of an infinite number of supports \citep{mandallaz2013b}. In all other cases, one can only try to get a reasonable approximation of $\bar{\pmb{Z}}$.\par

One possibility to approximate the exact mean $\bar{\pmb{Z}}$ is shown in Fig. \ref{fig:exh_nexh_and_boundweights_a}, which illustrates the implemented solution to the exhaustive use of the auxiliary information described in \citet{mandallaz2013b}. In order for all of the wall-to-wall auxiliary information to be exploited, the spatial arrangement of the supports were tesselated to form a perfect partition over the inventory area as is the case with the dark green polygons (squares tiles in this case). Is has to be noted that this would perfectly enable for calculating the exact mean $\bar{\pmb{Z}}$ in the \textit{finite} population approach, i.e. deriving $\pmb{Z}(x)$ for the entire finite population of supports and consequently calculating the exact mean $\bar{\pmb{Z}}$. While this is not equal to the exact mean $\bar{\pmb{Z}}$ in the infinite population approach, $n_1$ is still expected to be reasonably large to assume a good approximation of $\bar{\pmb{Z}}$ as long as the size of the supports are not unreasonably large. Whereas this implementation provides a convenient flexibility to switch between extimators of both the finite and infinite approach using the \textit{same} data set, it can also impose practical drawbacks. One is that a perfect tesselation by the supports strongly depends on the distance between the sample locations of $s_1$ in combination with the spatial extent of the support. Since in practice the support size will rather be chosen in order to achieve a best possible explanatory power of the regression model, thus minimizing the residual variation, a perfect tesselation might not always be feasible. In the infinite population frame however, the supports are also allowed to overlap if this seems necessary to acquire a sufficiently large sample $n_1$ of $\pmb{Z}(x)$ to get a reasonable approximation of $\bar{\pmb{Z}}$. This is again because $\pmb{Z}(x)$ only refers to the sample point and has no spatial association. With this respect, the infinite population approach can thus provide more flexibility than the finite approach. One could also consider the use of different support sizes per explanatory variable as long as they are consistently used at all sample locations.

\begin{figure}[htb]
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
    \resizebox{0.8\hsize}{!}{\includegraphics{fig/boundaryweight_graphic(left).eps}}%
		\caption{} \label{fig:exh_nexh_and_boundweights_a}
		\end{subfigure}
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
   \resizebox{0.8\hsize}{!}{\includegraphics{fig/boundaryweight_graphic(right).eps}}%
		\caption{} \label{fig:exh_nexh_and_boundweights_b}
	\end{subfigure}
\caption{Concept of \textbf{(a)} exhaustive and \textbf{(b)} non-exhaustive calculation of explanatory variables including boundary adjustment at the support level. Auxiliary data are in both cases available over the entire inventory area marked by the large rectangle. A vector of explanatory variables $\pmb{Z}(x)$ is calculated within the supports (small squares)  at each sample location $x$ (points) that falls into the forest area (green underlying polygon).}
\label{fig:exh_nexh_bw}
\end{figure}

An extension to the so-far published estimators by Mandallaz is the consideration of a \textit{\textbf{boundary adjustment}}. In forest inventories, the sample is often restricted to those sample locations located within the forest area. In case a consistent forest definition can be applied to both the $s_2$ and $s_1$ sample (e.g. by a polygon forest mask layer), it might be desired to restrict the calculation of the explanatory variables to the forest area within the given support (see Fig. \ref{fig:exh_nexh_bw}). This method was suggested in \citet{mandallaz2013b} and led to an improvement in estimation precision. In order to ensure an unbiased calculation of either $\hat{\bar{\pmb{Z}}}$ or $\bar{\pmb{Z}}$, the respective means have then to be calculated as the \textit{weighted} mean (Eq. \ref{eq:wmeanZ}) where the weight $w(x)$ is equal to the percentage of forested area within the support of sample location $x$.

\begin{equation}\label{eq:wmeanZ}
  \hat{\bar{\pmb{Z}}}=\frac{\sum_{x\in{s_1}}w(x)\pmb{Z}(x)}{\sum_{x\in{s_1}}w(x)}
\end{equation}

% --------------------------- %
\subsubsection{Application}

To demonstrate the use of the global two-phase estimators, we will use the \code{grisons} data set that comes with installing the package from the CRAN repository. The data set contains data from a simple (i.e. non-cluster) two-phase forest inventory conducted in 2007 that was used in \citet{mandallaz2013b} as a case study. The $s_1$ sample is comprised of 306 sample locations arranged on a systematic grid containing auxiliary information in the form of LiDAR canopy height metrics (\code{mean}, \code{stddev}, \code{max}, \code{q75}). For a systematic subsample of 67 ($s_2$ sample), terrestrial information of the timber volume per hectare (\code{tvol}) on the sample plot level is provided from a terrestrial survey. We can load \pkg{forestinventory} and examine the \code{grisons} data set in the \proglang{R} environment as follows:

<<echo=FALSE>>=
options(width=10000) 
@

\begin{small}
<<eval=FALSE>>=
library(forestinventory)
data("grisons", package = "forestinventory")
head(grisons)
@
\end{small}

\begin{small}
<<eval=TRUE, echo=FALSE>>=
library(forestinventory)
set.seed(666);print(head(grisons[sample(1:306,10),c(1,3,4,5,6,7,8,9)], 10),row.names=c(1:10))
@
\end{small}

Estimates can be made using the \code{onephase()}, \code{twophase()} or \code{threephase()} functions. The data frame inputted to these functions must have the structure where each row corresponds to a unique sample location and the columns specify the attributes associated to that respective sample location. Attributes that are missing, e.g. because they are associated with sample locations that were not selected in the subsample for the subsequent phase, should be designated as \code{NA} and the phase membership is encoded as numeric.

For global two-phase estimation, we have to specify

\begin{itemize}
  \itemsep0em
  \item the regression model (\code{formula}) as specified in the \code{lm}()-function \citep{R}
  \item the inputted \code{data.frame} containing the inventory information (\code{data})
  \item the \code{list}-object \code{phase_id} containing: the \code{phase.col} argument identifying the name of the column specifying membership to $s_1$ or $s_2$, and the \code{terrgrid.id} argument specifying which numeric value indicates $s_2$ membership in that column
  \item the name of the column containing the weights $w(x)$ of the boundary adjustments (optional)
\end{itemize}

The \textbf{non-exhaustive estimator with boundary weight adjustment} can thus be applied as follows:

\begin{small}
<<>>=
reg2p_nex <- twophase(formula=tvol ~ mean + stddev + max + q75,
                   data=grisons,
                   phase_id=list(phase.col = "phase_id_2p", terrgrid.id = 2),
                   boundary_weights = "boundary_weights")
@
\end{small}

The \code{twophase()} function creates an \code{S3} object of class \code{"twophase"} with subclass \code{"global"}. A readable \textbf{summary of the estimation results} can be obtained by passing this object to the \code{summary()} function, which automatically interprets what type of estimator was used and returns pertinent information such as the regression model formula, the point estimate (\code{estimate}), the g-weight and external variance (\code{g_variance} and \code{ext_variance}) as well as the sample sizes and the model R$^2$:

\begin{small}
<<>>=
summary(reg2p_nex)
@
\end{small}

For practical use, one should normally always prefer the g-weight variance over the external variance. This is because when we use internal models, the regression coefficients actually depend on the terrestrial sample realized by the sampling design. In contrast to the external variance, the g-weight variance accounts for this sampling variability which results in more reliable point and variance estimates and also enjoys better statistical calibration properties (g-weights). The external and g-weight variances are asymptotically equivalent but the external variance is really only included here in case the user wants to compare to another estimator where no g-weight variance exists.

The \textbf{exhaustive estimator} can be applied by additionally passing a vector containing the \textit{exact} means of the explanatory variables, i.e. $\bar{\pmb{Z}}$, to the optional argument \code{exhaustive}. This vector must be calculated beforehand in such a way that any desired boundary adjustment has already been applied. Note that the vector input to \code{exhaustive} must be in the same order that the \code{lm()}-function processes a \code{formula} object including the intercept term whose exact mean will always be 1. Particular caution must be taken if categorical variables are present because the \code{lm()}-function, which is internally used to set up the design-matrix, automatically creates dummy variables with one of the categories used as a reference. Using our \code{grisons} example, the correct order can always be extracted by the following \proglang{R}-code:


\begin{small}
<<eval=FALSE>>=
colnames(lm(formula = tvol ~ mean + stddev + max + q75, data = grisons, x = TRUE)$x)
@
\end{small}

The \textbf{exhaustive estimator} can be applied after defining the vector of exact means $\bar{\pmb{Z}}$ taken from \citet{mandallaz2013b}, denoted as \code{true.means.Z}:

\begin{small}
<<>>=
true.means.Z <- c(1, 11.39, 8.84, 32.68, 18.03)

reg2p_ex <- twophase(formula = tvol ~ mean + stddev + max + q75,
                    data = grisons,
                    phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
                    exhaustive = true.means.Z)
@
\end{small}

An alternative way to look at the estimation results without using the \code{summary()} is to query \code{reg2p_ex} directly:
\begin{small}
<<>>=
reg2p_ex$estimation
@
\end{small}
Note that both variances of the exhaustive estimation are smaller than those of the non-exhaustive estimation. This is essentially because we eliminated one component of uncertainty by substituting the estimated means of the explanatory variables $\hat{\bar{\pmb{Z}}}$ by their exact means $\bar{\pmb{Z}}$.


%--------------------------------------------------------------------------------------------------%
% ################################################################################################ %
%--------------------------------------------------------------------------------------------------%

\subsection{Small Area Estimators}
\label{sec:twophase_sae}

\subsubsection{Mathematical Background}

The \pkg{forestinventory} package provides three types of small area estimators each of which has an exhaustive and non-exhaustive form. We will use a different nomenclature for the non-exhaustive case in small area estimation since much of the existing literature shows preference for the label \textit{pseudo} to indicate that the mean of the explanatory variables within the small area was based on a finite sample. The main idea for all these small area estimators is to calculate the regression coefficient vector $\hat{\pmb{\beta}}_{s_2}$ and its variance-covariance matrix $\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}$ on the entire $s_2$ sample according to Eq. \ref{normequ_simple} and \ref{eq:estvarmatrix}, and subsequently use that to make predictions for sample locations restricted to small area $G$.\par

%----------------------------------------------- %
% \textbf{Small and Pseudo Small Area Estimator}\par

We first introduce the \textbf{small area estimator} (\textit{small}), which uses exhaustively computed explanatory variables, and its non-exhaustive version, the \textbf{\textit{pseudo}} \textbf{small area estimator} (\textit{psmall}). 

\begin{subequations}\label{eq:pest_2p_small_psmall}
\begin{align}
  \hat{Y}_{G,small,2p} & =\bar{\pmb{Z}}_G^t\hat{\pmb{\beta}}_{s_2} + \frac{1}{n_{2,G}}\hat{R}(x)  \label{eq:pointest_2p_small} \\
  \hat{Y}_{G,psmall,2p} & =\hat{\bar{\pmb{Z}}}_G^t\hat{\pmb{\beta}}_{s_2} + \frac{1}{n_{2,G}}\hat{R}(x) \label{eq:pepsmall}
\end{align}
\end{subequations}

In the equations for the point estimates (Eq. \ref{eq:pointest_2p_small} and \ref{eq:pepsmall}), we see that the globally derived regression coefficients are applied to the exhaustively or non-exhaustively calculated means of the explanatory variables ($\bar{\pmb{Z}}_G$, $\hat{\bar{\pmb{Z}}}_G$) which are now only based on the first-phase sample $s_{1,G}$ located within small area $G$. A potential bias of the regression model predictions in the small area $G$, due to fitting the regression model with data also outside of $G$, is then corrected by adding the mean of the empirical model residuals in $G$. This is called the \textit{bias} or \textit{residual correction} term.

The package provides the \textit{g-weight} variance for \textit{small} and \textit{psmall} respectively (Eq. \ref{eq:var_2p_reg_small}, \ref{eq:var_2p_reg_psmall}) as well as the  \textit{external variance} (Eq. \ref{eq:varext_2p_reg_small}, \ref{eq:varext_2p_reg_psmall}). Again note that all components are restricted to those available at the sample locations in the small area ($s_{1,G}$ and $s_{2,G}$), with exception of the regression coefficient components $\hat{\pmb{\beta}}_{s_2}$ and $\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}$.

\begin{subequations}\label{eq:var_2p_small_psmall}
\begin{align}
  \hat{\var}(\hat{Y}_{G,small,2p}) & := \bar{\pmb{Z}}_G^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\bar{\pmb{Z}}_G
    + \frac{1}{n_{2,G}}\frac{1}{n_{2,G}-1}\sum_{x \in s_{2,G}} \Big(\hat{R}(x)-\bar{\hat{R}}_{2,G}\Big)^2  \label{eq:var_2p_reg_small} \\
  \hat{\var}(\hat{Y}_{G,psmall,2p}) & := \hat{\bar{\pmb{Z}}}_G^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\hat{\bar{\pmb{Z}}}_G
  + \hat{\pmb{\beta}}_{s_2}^t\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}_G}\hat{\pmb{\beta}}_{s_2}
  + \frac{1}{n_{2,G}}\frac{1}{n_{2,G}-1}\sum_{x \in s_{2,G}} \Big(\hat{R}(x)-\bar{\hat{R}}_{2,G}\Big)^2  \label{eq:var_2p_reg_psmall}
\end{align}
\end{subequations}

\begin{subequations}\label{eq:varext_2p_small_psmall}
\begin{align}
  \hat{\var}_{ext}(\hat{Y}_{G,small,2p}) & := \frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{R}(x))  \label{eq:varext_2p_reg_small} \\
  \hat{\var}_{ext}(\hat{Y}_{G,psmall,2p}) & := \frac{1}{n_{1,G}}\hat{\var}_{s_{2,G}}(Y(x)) + \Big(1-\frac{n_{2,G}}{n_{1,G}}\Big)\frac{1}{n_{2,G}}\hat{\var}_{s_{2_G}}(\hat{R}(x)) \label{eq:varext_2p_reg_psmall}
\end{align}
\end{subequations}
where $\hat{\var}_{s_{2,G}}$ indicates taking the sample variance over $s_{2,G}$. If boundary adjustment is applied, the simple mean of the explanatory variable over the small area $\hat{\bar{\pmb{Z}}}_G=\frac{1}{n_{1,G}}\sum_{x \in s_{1,G}}\pmb{Z}(x)$ is replaced by its weighted version $\hat{\bar{\pmb{Z}}}_G=\frac{\sum_{x\in{s_{1,G}}}w(x)\pmb{Z}(x)}{\sum_{x\in{s_{1,G}}}w(x)}$, and likewise for exhaustively used auxiliary information.



%------------------------------------------------------------- %
% \textbf{Synthetic and Pseudo Synthetic Estimator}\par

The \textbf{synthetic estimator} (\textit{synth}) and \textbf{pseudo synthetic estimator} \textit{psynth} are commonly applied when no terrestrial sample is available within the small area $G$ (i.e. $n_{2,G}=0$). In this case, the point estimates (Eq. \ref{eq:pointest_2p_reg_synth} and \ref{eq:pointest_2p_reg_psynth}) are based \textit{only} on the predictions generated by applying the globally derived regression model to the auxiliary vectors $\bar{\pmb{Z}}_G$ and $\hat{\bar{\pmb{Z}}}_G$ respectively. However, the bias correction using the observed residuals $\hat{R}(x)$ is not applied as was the case in the small and pseudo small area estimator (Eq. \ref{eq:pointest_2p_small} and \ref{eq:pepsmall}). Thus, the (pseudo) synthetic estimator is unbiased \textbf{only} if $\frac{1}{n_{2,G}}\sum_{x \in s_{2,G}}\hat{R}(x)=0$. However, this assumption is unlikely to be fullfilled in practice resulting in a potentially unobservable design-based bias equal to $-\frac{1}{\lambda(G)}\int_G R(x)$. Also note that the residual variation can no longer be considered in the g-weight variance (Eq. \ref{eq:var_2p_reg_synth} and \ref{eq:var_2p_reg_psynth}). Therefore, the synthetic estimators will usually have a smaller variance than estimators incorporating the regression model uncertainties, but at the cost of a potential bias. Due to the absence of available residuals in $G$, there is also no external variance form for the synthetic and pseudo synthetic estimator.

\begin{subequations}\label{eq:pest_2p_synth_psynth}
\begin{align}
  \hat{Y}_{G,synth,2p} & =\bar{\pmb{Z}}_G^t\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_synth} \\
  \hat{Y}_{G,psynth,2p} & =\hat{\bar{\pmb{Z}}}_G^t\hat{\pmb{\beta}}_{s_2} \label{eq:pointest_2p_reg_psynth} \\
  \hat{\var}(\hat{Y}_{G,synth,2p}) & = \bar{\pmb{Z}}_G^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\bar{\pmb{Z}}_G \label{eq:var_2p_reg_synth} \\
  \hat{\var}(\hat{Y}_{G,psynth,2p}) & = \hat{\bar{\pmb{Z}}}_G^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\beta}}_{s_2}}\hat{\bar{\pmb{Z}}}_G
  + \hat{\pmb{\beta}}_{s_2}^t\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}_G}\hat{\pmb{\beta}}_{s_2}  \label{eq:var_2p_reg_psynth}
\end{align}
\end{subequations}

where the variance-covariance matrix of the auxiliary vector $\hat{\bar{\pmb{Z}}}_G$ is estimated by
\begin{equation}\label{estvarcovaux_G}
\hat{\Sigma}_{\hat{\bar{\pmb{Z}}}_{G}}=
\frac{1}{n_{1,G}(n_{1,G}-1)}\sum_{x\in{s_{1,G}}}
(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}}_{G})(\pmb{Z}(x)-\hat{\bar{\pmb{Z}}}_{G})^t
\end{equation}

%------------------------------------------------------------- %
% \textbf{Extended Synthetic and Extended Pseudo Synthetic Estimator}\par

The synthetic estimators, \textit{synth} and \textit{psynth}, have attractively compact formulas but come with the downside of potential bias in their point estimates which can make the variances seem deceptively. The \textit{small} and \textit{psmall} estimators overcome this issue by using a bias correction term, i.e. $\frac{1}{n_{2,G}}\sum_{x \in s_{2,G}}\hat{R}(x)$. The motivation behind the \textbf{\textit{extended}} \textbf{synthetic} and \textbf{\textit{extended}} \textbf{pseudo synthetic estimator} (\textit{extsynth} and \textit{extpsynth}) is to use the same mathematically elegant formulas of the (pseudo) synthetic estimators while at the same time ensuring that the empirical residuals of the prediction model in the entire area $F$ and the small area $G$ are by construction both zero at the same time. This is accomplished by extending the vector of auxiliary information $\pmb{Z}(x)$ by a binary categorical indicator variable $I_G(x)$ which takes the value 1 if the sample location $x$ lies inside the target small area $G$ and is otherwise set to 0. Recalling that linear models fitted using OLS have zero mean residual property by construction, this leads to unbiased point estimates and is also true if categorical variables are included in the model. The new \textit{extended} auxiliary vector thus becomes $\pmb{\mathbb{Z}}^t(x)=(\pmb{Z}^t(x),I_G(x))$ and can be used to replace its non-extended counterpart $\pmb{Z}^t(x)$ whereever it is used in Eq. \ref{eq:pest_2p_synth_psynth} and \ref{estvarcovaux_G}. Note that the package functions internally extend the data set by the indicator variable if the \textit{extsynth} or \textit{extpsynth} estimator is called.

Not every equation needs to be re-written here, but to give an example of the notational change, the regression coefficient under extended model approach becomes

\begin{equation}\label{ext_normequ_simple}
  \hat{\pmb{\theta}}_{s_2}=\Big(\frac{1}{n_2}\sum_{x\in{s_2}}\pmb{\mathbb{Z}}(x)\pmb{\mathbb{Z}}^t(x) \Big)^{-1} \Big(\frac{1}{n_2}\sum_{x\in{s_2}}Y(x)\pmb{\mathbb{Z}}(x)\Big)
\end{equation}

The point estimates and their g-weight variances can then be re-written as

\begin{subequations}\label{eq:pest_2p_extsynth_extpsynth}
\begin{align}
\hat{Y}_{G,extsynth,2p} & = \bar{\pmb{\mathbb{Z}}}^t_{G}\hat{\pmb{\theta}}_{s_2} \label{eq:pointest_2p_extsynth} \\
\hat{Y}_{G,extpsynth,2p} & =\hat{\bar{\pmb{\mathbb{Z}}}}_{G}^t\hat{\pmb{\theta}}_{s_2} \label{eq:pointest_2p_extsynth} \\
\hat{\var}(\hat{Y}_{G,extsynth,2p}) & = \bar{\pmb{\mathbb{Z}}}^t_{G}\hat{\pmb{\Sigma}}_{\hat{\pmb{\theta}}_{s_2}}\bar{\pmb{\mathbb{Z}}}_{G} \label{eq:var_2p_extsynth} \\
\hat{\var}(\hat{Y}_{G,extpsynth,2p})& =
\hat{\bar{\pmb{\mathbb{Z}}}}_{G}^t\hat{\pmb{\Sigma}}_{\hat{\pmb{\theta}}_{s_2}}
\hat{\bar{\pmb{\mathbb{Z}}}}_{G}
+ \hat{\pmb{\theta}}^t_{s_2}\hat{\Sigma}_{\hat{\bar{\pmb{\mathbb{Z}}}}_{G}}\hat{\pmb{\theta}}_{s_2} \label{eq:var_2p_extpsynth}
\end{align}
\end{subequations}

While the formulas look similar to the synthetic estimators, note that a decomposition of $\hat{\pmb{\theta}}_{s_2}$ reveals that the residual correction term is now included in the regression coefficient $\hat{\pmb{\theta}}_{s_2}$ \citep{mandallaz2016} and thus the estimates are asymptotically design-unbiased.

The package also provides the external variance for both the \textit{extended} synthetic and \textit{extended} pseudo synthetic estimator. Note that neither the extended model approach nor external variance estimates are possible in the absence of terrestrial samples and thus model residuals in $G$, which is precisely when one must rely on the (pseudo) synthetic estimates. The external variance forms of \textit{extsynth} and \textit{extpsynth} are

\begin{subequations}\label{eq:ext_varexternal_2p_extsynth}
\begin{align}
  \hat{\var}_{ext}(\hat{Y}_{G,extsynth,2p}) & = \frac{1}{n_{2,G}}\hat{\var}_{s_{2,G}}(\hat{\mathbb{R}}(x)) \label{eq:ext_varexternal_2p_extsynth} \\
  \hat{\var}_{ext}(\hat{Y}_{G,extpsynth,2p}) & = \frac{1}{n_{1,G}}\hat{\var}_{s_{2,G}}(Y(x)) + \Big(1-\frac{n_{2,G}}{n_{1,G}}\Big)\frac{1}{n_{2,G}}\hat{\var}_{s_{2_G}}(\hat{\mathbb{R}}(x)) \label{eq:ext_varexternal_2p_extpsynth}
\end{align}
\end{subequations}
where $\hat{\mathbb{R}}(x)$ are the empirical residuals under the extended auxiliary vector.

To summarize, the (pseudo) synthetic estimator can be applied whether terrestrial inventory sample is found in the small area or not, but has a deceptively small g-weight variance due to its potential bias.  When terrestrial sample is observed in the small area, we can produce (asymptotically) design-unbiased estimates and variances using either \textit{small} or \textit{psmall} which remove this bias directly with a mean residual term, or more elegantly with \textit{extsynth} or \textit{extpsynth} which simply use the same synthetic formulas while including an indicator variable for the small area in the model formula to remove the bias by construction in OLS.


%------------------------------------------------------------- %
\subsubsection{Application}

Small area estimates in the \pkg{forestinventory} package can be applied by specifying the optional argument \code{small_area}. The input data set has to include an additional column of class \code{factor} that describes the small area membership of the sample location represented by that row. The argument \code{small_area} requires a \code{list}-object that comprises

\begin{itemize}
  \itemsep0em
  \item the name of the column specifiying the small area of each observation (\code{sa.col})
  \item a vector specifying the small area(s) for which estimations are desired (\code{areas})
  \item the argument \code{unbiased} that controls which of the three available estimators is applied
\end{itemize}

In order to apply the \textbf{pseudo small area estimator} (\textit{psmall}) with boundary adjustment, we set \code{unbiased=TRUE} as well as the optional argument \code{psmall=TRUE}:
\begin{small}
<<>>=
psmall_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, data = grisons,
                      phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
                      boundary_weights = "boundary_weights",
                      small_area = list(sa.col = "smallarea", areas = c("A", "B"),
                                        unbiased = TRUE),
                      psmall = TRUE)
summary(psmall_2p)
@
\end{small}

The small area functions all return an \code{S3} object of class \code{"twophase"} with subclass \code{"smallarea"}. In addition to global estimation, the \code{estimation} object now comprises the estimates and variances for all small areas (column \code{area}). We can view the sample sizes by looking into the object itself
\begin{small}
<<>>=
psmall_2p$samplesizes
@
\end{small}

The \textbf{extended pseudo synthetic estimator} (\textit{extpsynth}) can be applied by setting \code{unbiased=TRUE} and leaving the optional argument \code{psmall} to its default value of \code{FALSE}:
\begin{small}
<<>>=
extpsynth_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, data = grisons,
                         phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
                         boundary_weights = "boundary_weights",
                         small_area = list(sa.col = "smallarea", areas = c("A", "B"),
                                           unbiased = TRUE))
extpsynth_2p$estimation
@
\end{small}

The \pkg{forestinventory} package automatically includes the indicator variable for the small area behind the scenes so there is no need for the user to implement it. Notice that the $R^2$s (\code{r.squared}) under the \textit{extpsynth} estimator vary between the small areas, while they are identical under the \textit{psmall} estimator. This is because under the \textit{extpsynth} estimator, the regression model is recalculated for each small area estimation after adding the indicator variable for the respective small area in the globally derived design matrix. In case of the  \textit{psmall} estimator, the regression model stays the same for each small area estimation. Although the results of both estimators should always be close to each other, we recommend applying both estimators and compare the results afterwards in order to reveal unsuspected patterns in the data, particularly in the case of cluster sampling (see Section \ref{sec:speccas_and_scen}).\par

Setting the argument \code{unbiased=FALSE} applies the \textbf{pseudo synthetic estimator} to the selected small areas. Note that in the \code{grisons} data set, all small areas possess much more than the suggested minimum number of terrestrial observations (a rule of thumb is that $n_{2,G} \geq 6$) required to produce reliable design-unbiased estimates. Hence, choosing to use \textit{psynth} is probably not desireable and is just applied here for demonstration purposes. The function will in this case ignore the terrestrial information in the data set.


\begin{small}
<<>>=
psynth_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, data = grisons,
                      phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
                      boundary_weights = "boundary_weights",
                      small_area = list(sa.col = "smallarea", areas = c("A", "B"),
                                        unbiased = FALSE))
psynth_2p$estimation
@
\end{small}

We see here that the \textit{psynth} variances are almost only half the variances of the \textit{psmall} and \textit{extended psynth} estimators. However, \textit{psmall} and \textit{extended psynth} are design unbiased and their variances reflect the fact that they account for potential bias of the regression model predictions. The g-weight variance of \textit{psynth} completely neglects a potential bias and as a result risks severely overstating the estimation precision.\par

The \textbf{exhaustive versions} of the small area estimators (Eq. \ref{eq:pointest_2p_small}, \ref{eq:var_2p_reg_small}, \ref{eq:varext_2p_reg_small}, \ref{eq:pointest_2p_reg_synth}, \ref{eq:var_2p_reg_synth}) are specified via the optional argument \code{exhaustive}. Its application requires that we know the exact means of all explanatory variables within the small area(s) of interest. In contrast to the \textit{global} estimators, the exact means have now to be delivered in the form of a \code{data.frame}, where each row corresponds to a small area, and each column specifies the exact mean of the respective explanatory variable. Note that likewise the case of global estimation, the order of the explanatory variables in the data frame has to match the order in which they appear in the design matrix defined by the \code{lm()}-function in \proglang{R}. In order to tell \proglang{R} which row describes which small area, the row names have to match the respective names of the small areas specified in the \code{areas} argument.

For the \code{grisons} data set, the exact means of the explanatory variables for the small areas used in \citet{mandallaz2013b} are thus defined by
\begin{small}
<<eval=FALSE>>=
colnames(lm(formula = tvol ~ mean + stddev + max + q75, data = grisons, x = TRUE)$x)
@
\end{small}
\begin{small}
<<>>=
true.means.Z.G <- data.frame(Intercept = rep(1, 4),
                         mean = c(12.85, 12.21, 9.33, 10.45),
                         stddev = c(9.31, 9.47, 7.90, 8.36),
                         max = c(34.92, 35.36, 28.81, 30.22),
                         q75 = c(19.77, 19.16, 15.40, 16.91))
rownames(true.means.Z.G) <- c("A", "B", "C", "D")
@
\end{small}
\begin{small}
<<>>=
true.means.Z.G
@
\end{small}

For example, the \textbf{extended synthetic estimator} (\textit{extsynth}) can then be applied by
\begin{small}
<<>>=
extsynth_2p <- twophase(formula = tvol ~ mean + stddev + max + q75, data = grisons,
                        phase_id = list(phase.col = "phase_id_2p", terrgrid.id = 2),
                        small_area = list(sa.col ="smallarea", areas = c("A", "B"),
                                          unbiased = TRUE),
                        exhaustive = true.means.Z.G)
extsynth_2p$estimation
@
\end{small}

Just as in the global case, we see that the variance has again been significantly decreased by substituting the \textit{exact} auxiliary means and both first phase sample sizes are now infinity. Note that the function extracts the required exact means for small area \code{"A"} and \code{"B"} from the complete set of exact means defined in \code{true.means.Z.G}.

\newpage